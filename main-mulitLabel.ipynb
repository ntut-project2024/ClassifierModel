{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.DevConf import DevConf\n",
    "DEV_CONF = DevConf(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\henry\\.conda\\envs\\torch-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.AttnBlocksConf import AttnBlocksConf\n",
    "from model.BertDecoder.SentiClassifier import SentiClassifier\n",
    "from model.CombinationModel import CombinationModel\n",
    "from utils.const import BlockType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = SentiClassifier(6, AttnBlocksConf(768, 12, nKVHead=6), BlockType.CROSS, devConf=DEV_CONF)\n",
    "model = CombinationModel(nClass=6, decoder=mapper, devConf=DEV_CONF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-multilingual-cased\", cache_dir='./cache/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/archive/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(idx)\n",
    "        text = self.df.iloc[idx]['ABSTRACT']\n",
    "        label = torch.tensor([self.df.iloc[idx][i] for i in [\"Computer Science\",\"Physics\",\"Mathematics\",\"Statistics\",\"Quantitative Biology\",\"Quantitative Finance\"]])\n",
    "        return text, label\n",
    "        # return self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=128), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    # print(texts)\n",
    "    return tokenizer(texts, return_tensors='pt', padding='max_length', truncation=True, max_length=512).to(device=DEV_CONF.device), torch.stack(labels).to(DEV_CONF.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25663ed8e10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def seed_worker(worker_id):\n",
    "#     worker_seed = torch.initial_seed() % 2**32\n",
    "#     np.random.seed(worker_seed)\n",
    "#     random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(train, tokenizer)\n",
    "\n",
    "datasize = len(dataset)\n",
    "splitIndex = int(datasize * 0.2)\n",
    "trainDataSize = datasize - splitIndex\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [trainDataSize, splitIndex])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, collate_fn=collect_fn, batch_size=8, shuffle=True,\n",
    "    generator=g)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, collate_fn=collect_fn, batch_size=1, shuffle=True,\n",
    "    generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16778 4194\n"
     ]
    }
   ],
   "source": [
    "print(trainDataSize, splitIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "epochs = 1\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, train_loader, loss_fn, optimizer, epochs):\n",
    "    model.train()\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, label) in enumerate(train_loader):\n",
    "            # print(data['input_ids'])\n",
    "            # break\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**data)#, NoGradBert=False)\n",
    "            loss = loss_fn(output, label.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 100 == 99:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Batch {i+1}/{len(train_loader)} - Loss: {loss.item()}\")\n",
    "                writer.add_scalar('Loss/train', loss.item(), i + 1)\n",
    "    writer.flush()\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Batch 100/2098 - Loss: 0.5620404481887817\n",
      "Epoch 1/1 - Batch 200/2098 - Loss: 0.38083696365356445\n",
      "Epoch 1/1 - Batch 300/2098 - Loss: 0.2401605248451233\n",
      "Epoch 1/1 - Batch 400/2098 - Loss: 0.30665573477745056\n",
      "Epoch 1/1 - Batch 500/2098 - Loss: 0.26897913217544556\n",
      "Epoch 1/1 - Batch 600/2098 - Loss: 0.22492913901805878\n",
      "Epoch 1/1 - Batch 700/2098 - Loss: 0.47321945428848267\n",
      "Epoch 1/1 - Batch 800/2098 - Loss: 0.1846269965171814\n",
      "Epoch 1/1 - Batch 900/2098 - Loss: 0.28365057706832886\n",
      "Epoch 1/1 - Batch 1000/2098 - Loss: 0.3762596547603607\n",
      "Epoch 1/1 - Batch 1100/2098 - Loss: 0.4708443880081177\n",
      "Epoch 1/1 - Batch 1200/2098 - Loss: 0.12179668992757797\n",
      "Epoch 1/1 - Batch 1300/2098 - Loss: 0.1721089780330658\n",
      "Epoch 1/1 - Batch 1400/2098 - Loss: 0.11529495567083359\n",
      "Epoch 1/1 - Batch 1500/2098 - Loss: 0.15808045864105225\n",
      "Epoch 1/1 - Batch 1600/2098 - Loss: 0.18334411084651947\n",
      "Epoch 1/1 - Batch 1700/2098 - Loss: 0.23328182101249695\n",
      "Epoch 1/1 - Batch 1800/2098 - Loss: 0.11077529191970825\n",
      "Epoch 1/1 - Batch 1900/2098 - Loss: 0.3854753375053406\n",
      "Epoch 1/1 - Batch 2000/2098 - Loss: 0.15334659814834595\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_fn(model, train_loader, loss_fn, optimizer, epochs)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinationModel(\n",
       "  (distilBert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): SentiClassifier(\n",
       "    (mapper): CACBlocks(\n",
       "      (_mha): ModuleList(\n",
       "        (0-5): 6 x MHABlock(\n",
       "          (_mha): Attention(\n",
       "            (qProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (kvProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (outProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ffn): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (outNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (_Q): Linear(in_features=1, out_features=768, bias=False)\n",
       "  )\n",
       "  (outProj): Linear(in_features=768, out_features=6, bias=True)\n",
       "  (activate): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id = 13\n",
    "# sample = tokenizer(dataset[id][0], return_tensors='pt', padding='max_length', truncation=True, max_length=512).to(device=DEV_CONF.device)\n",
    "# output = torch.where(model(**sample) > 0.5, 1, 0)\n",
    "# print(output)\n",
    "# print(dataset[id][1])\n",
    "# array = output.to(\"cpu\").squeeze().numpy()\n",
    "# dataset_array = dataset[id][1].numpy()\n",
    "# for i in range(6):\n",
    "#     print(array[i], dataset_array[i])\n",
    "# ans = torch.eq(output.to(\"cpu\"), dataset[id][1])\n",
    "# print(ans)\n",
    "# print(torch.all(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = [0] * 6\n",
    "# testdata = train.sample(1000)\n",
    "# test_dataset = MyDataset(testdata, tokenizer)\n",
    "\n",
    "# for data in test_dataset:\n",
    "#     # print(data[1][0])\n",
    "#     sample = tokenizer(data[0], return_tensors='pt', padding='max_length', truncation=True, max_length=512).to(device=DEV_CONF.device)\n",
    "#     output = torch.where(model(**sample) > 0.5, 1, 0)\n",
    "#     ansList = torch.eq(output.squeeze().to(\"cpu\"), data[1])\n",
    "#     for i, ans in enumerate(ansList):\n",
    "#         # print(ans)\n",
    "#         if ans:\n",
    "#             acc[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    acc = [[[0, 0], [0, 0]] for _ in range(6)]\n",
    "    for (data, label) in test_loader:\n",
    "        output = torch.where(model(**data) > 0.25, 1, 0).squeeze().cpu().numpy()\n",
    "        ans = label.squeeze().squeeze().cpu().numpy()\n",
    "        for i in range(6):\n",
    "            acc[i][output[i]][ans[i]] += 1\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1816, 84], [677, 1617]]\n",
      "[[2795, 179], [223, 997]]\n",
      "[[2839, 274], [197, 884]]\n",
      "[[2855, 326], [259, 754]]\n",
      "[[4060, 87], [14, 33]]\n",
      "[[4154, 40], [0, 0]]\n"
     ]
    }
   ],
   "source": [
    "for matrix in acc:\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[1606, 887], [66, 1635]]\n",
    "[[2565, 453], [154, 1022]]\n",
    "[[2581, 455], [179, 979]]\n",
    "[[1836, 1278], [112, 968]]\n",
    "[[4074, 0], [120, 0]]\n",
    "[[4154, 0], [40, 0]]\n",
    "\n",
    "[[1513, 980], [45, 1656]]\n",
    "[[2438, 580], [114, 1062]]\n",
    "[[2727, 309], [227, 931]]\n",
    "[[2112, 1002], [155, 925]]\n",
    "[[4074, 0], [120, 0]]\n",
    "[[4154, 0], [40, 0]]\n",
    "\n",
    "[[1885, 608], [102, 1599]]\n",
    "[[2640, 378], [111, 1065]]\n",
    "[[2581, 455], [143, 1015]]\n",
    "[[2388, 726], [135, 945]]\n",
    "[[4073, 1], [111, 9]]\n",
    "[[4154, 0], [40, 0]]\n",
    "\n",
    "[[1893, 600], [63, 1638]]\n",
    "[[2732, 286], [99, 1077]]\n",
    "[[2646, 390], [127, 1031]]\n",
    "[[2474, 640], [59, 1021]]\n",
    "[[4007, 67], [41, 79]]\n",
    "[[4116, 38], [12, 28]]\n",
    "\n",
    "[[1850, 643], [59, 1642]]\n",
    "[[2556, 462], [54, 1122]]\n",
    "[[2667, 369], [136, 1022]]\n",
    "[[2804, 310], [180, 900]]\n",
    "[[4018, 56], [44, 76]]\n",
    "[[4145, 9], [27, 13]]\n",
    "\n",
    "[[1870, 623], [108, 1593]]\n",
    "[[2322, 696], [83, 1093]]\n",
    "[[2450, 586], [107, 1051]]\n",
    "[[2403, 711], [123, 957]]\n",
    "[[4038, 36], [69, 51]]\n",
    "[[4150, 4], [25, 15]]\n",
    "\n",
    "[[1585, 908], [38, 1663]]\n",
    "[[2578, 440], [111, 1065]]\n",
    "[[2755, 281], [209, 949]]\n",
    "[[2377, 737], [93, 987]]\n",
    "[[4035, 39], [60, 60]]\n",
    "[[4154, 0], [40, 0]]\n",
    "\n",
    "[[1656, 837], [45, 1656]]\n",
    "[[2680, 338], [144, 1032]]\n",
    "[[2761, 275], [203, 955]]\n",
    "[[2674, 440], [223, 857]]\n",
    "[[4048, 26], [73, 47]]\n",
    "[[4153, 1], [34, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "microacc = [[0, 0], [0, 0]]\n",
    "for i in range(6):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            microacc[j][k] += acc[i][j][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18519, 990], [1370, 4285]]\n"
     ]
    }
   ],
   "source": [
    "print(microacc) # microaveraging, macroaveraging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[16816, 3073], [671, 4604]]\n",
    "\n",
    "[[17018, 2871], [701, 4574]]\n",
    "\n",
    "[[17721, 2168], [642, 4633]]\n",
    "\n",
    "[[17868, 2021], [401, 4874]]\n",
    "\n",
    "[[18040, 1849], [500, 4775]]\n",
    "\n",
    "[[17233, 2656], [515, 4760]]\n",
    "\n",
    "[[17484, 2405], [551, 4724]]\n",
    "\n",
    "[[17972, 1917], [722, 4553]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.757736516357206\n",
      "Precision: 0.8123222748815165\n",
      "F1: 0.7840805123513266\n",
      "Acc: 0.9062152281036401\n"
     ]
    }
   ],
   "source": [
    "recall = microacc[1][1] / (microacc[1][1] + microacc[1][0])\n",
    "precision = microacc[1][1] / (microacc[1][1] + microacc[0][1])\n",
    "f1 = 2 * recall * precision / (recall + precision)\n",
    "acc = (microacc[0][0] + microacc[1][1]) / (microacc[0][0] + microacc[1][1] + microacc[0][1] + microacc[1][0])\n",
    "print(f\"Recall: {recall}\\nPrecision: {precision}\\nF1: {f1}\\nAcc: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: 0.8854976303317535\n",
    "Precision: 0.6786285050123493\n",
    "F1: 0.7683829577233097\n",
    "Acc: 0.8880941026863773\n",
    "\n",
    "Recall: 0.8671090047393365\n",
    "Precision: 0.6143720617864339\n",
    "F1: 0.7191823899371069\n",
    "Acc: 0.8580511842314418\n",
    "\n",
    "Recall: 0.8782938388625593\n",
    "Precision: 0.6812233495074254\n",
    "F1: 0.7673070553163299\n",
    "Acc: 0.8883325385471308\n",
    "\n",
    "Recall: 0.9239810426540285\n",
    "Precision: 0.7068890500362581\n",
    "F1: 0.8009860312243221\n",
    "Acc: 0.9037513908758544\n",
    "\n",
    "Recall: 0.9052132701421801\n",
    "Precision: 0.7208635265700483\n",
    "F1: 0.8025884528111605\n",
    "Acc: 0.9066523605150214\n",
    "\n",
    "Recall: 0.9023696682464455\n",
    "Precision: 0.6418554476806904\n",
    "F1: 0.7501378929950357\n",
    "Acc: 0.8739866475917978\n",
    "\n",
    "Recall: 0.8955450236966824\n",
    "Precision: 0.6626455323327255\n",
    "F1: 0.7616897774911319\n",
    "Acc: 0.8825305992687967\n",
    "\n",
    "Recall: 0.8631279620853081\n",
    "Precision: 0.70370942812983\n",
    "F1: 0.7753086419753087\n",
    "Acc: 0.8951279605786043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'weights/model-240520-2206-Cross-NoGrad-epoch1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('weights/model-240520-epoch1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
