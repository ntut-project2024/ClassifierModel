{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.DevConf import DevConf\n",
    "DEV_CONF = DevConf(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\python\\bert\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.AttnBlocksConf import AttnBlocksConf\n",
    "from model.BertDecoder.SentiClassifier import SentiClassifier\n",
    "from model.CombinationModel import CombinationModel\n",
    "from utils.const import BlockType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\python\\bert\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mapper = SentiClassifier(6, AttnBlocksConf(768, 12, nKVHead=6), BlockType.CROSS)\n",
    "model = CombinationModel(nClass=6, decoder=mapper, devConf=DEV_CONF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 6.0395e-01, -8.1428e-01, -1.3039e+00,  7.6129e-01, -6.2261e-01,\n",
      "         -3.5434e-01,  2.9630e-01,  2.2628e-01,  6.9910e-01, -2.7239e-01,\n",
      "         -6.3720e-01,  7.7931e-02, -7.7593e-01,  1.1518e-01, -1.9948e+00,\n",
      "         -1.2922e-01,  2.4402e-01,  4.2880e-02, -3.7178e-01,  5.0487e-01,\n",
      "         -6.2309e-01,  6.4418e-01,  7.8791e-01, -1.3183e+00, -2.6399e-01,\n",
      "          6.3105e-01, -7.6285e-01, -2.2449e-01,  6.4259e-01, -4.4549e-01,\n",
      "         -4.4144e-01,  1.8294e-02, -1.2467e+00, -4.8446e-01, -4.3753e-01,\n",
      "         -5.5458e-01, -1.4395e+00, -6.4573e-01, -8.7884e-01,  5.6430e-01,\n",
      "          1.0989e-01,  4.4094e-01,  7.1416e-01, -7.7362e-01,  1.2592e+00,\n",
      "          2.8197e-01, -8.2943e-01, -7.0778e-01,  1.4155e+00, -1.3312e+00,\n",
      "         -1.4538e-01,  3.8820e-01,  9.2164e-01,  1.0232e+00,  1.4780e-01,\n",
      "          7.7785e-01,  2.6167e-01,  7.4583e-01,  4.7644e-01, -2.8126e-01,\n",
      "          8.0821e-01, -2.2247e+00,  1.8166e-01, -1.1770e+00, -2.0425e+00,\n",
      "          1.2166e+00, -1.1641e-01, -1.7756e+00,  2.5923e-01,  1.4638e-01,\n",
      "         -1.3946e+00, -4.9857e-01, -2.4284e+00, -4.7013e-01,  1.7645e+00,\n",
      "         -5.8559e-01,  3.9509e-01,  6.1533e-01, -8.7763e-01, -3.3530e-01,\n",
      "          1.0692e+00, -2.8531e-01, -9.3225e-02, -8.4193e-01,  1.0699e+00,\n",
      "         -1.9360e-01,  8.7416e-02,  4.4011e-01,  9.7367e-01,  8.8581e-01,\n",
      "         -4.1594e-01, -1.1421e+00, -7.9571e-01, -5.9696e-01, -7.2418e-01,\n",
      "          1.2752e-01,  1.0383e+00, -6.1228e-01, -1.1697e+00,  4.2227e-01,\n",
      "         -1.8018e-01, -5.3181e-01, -9.3634e-01,  7.8211e-01, -6.5420e-01,\n",
      "         -7.9447e-01,  2.1331e-01,  8.0894e-02, -3.1670e-01, -9.1927e-01,\n",
      "          1.3034e+00,  1.0168e+00, -1.3859e+00, -1.5287e+00,  1.8527e+00,\n",
      "         -1.2841e+00,  5.5359e-01, -6.5421e-01,  7.8425e-01, -5.7289e-01,\n",
      "          2.7758e-01,  8.1401e-01,  8.4561e-01,  2.4074e-01, -2.4919e-01,\n",
      "         -1.0163e+00,  1.3161e+00, -3.0568e-01, -4.7473e-02, -9.9151e-01,\n",
      "          3.5630e-01,  8.9520e-01,  1.8253e+00,  1.1503e+00, -1.3757e-01,\n",
      "         -7.7355e-01,  1.3925e+00,  2.8542e-01, -2.4614e+00,  5.5543e-01,\n",
      "         -1.0547e+00, -6.6198e-01, -1.0960e+00,  2.4846e-01, -4.9541e-01,\n",
      "         -5.2716e-01, -2.2039e+00, -5.7499e-01,  1.1665e+00,  9.2148e-01,\n",
      "          1.3978e+00, -8.2830e-01,  7.5079e-01, -3.3886e-01, -6.7131e-01,\n",
      "         -2.4095e-01,  1.0524e+00,  7.5141e-01, -8.4104e-01,  5.4317e-01,\n",
      "          6.0197e-01,  1.4658e+00, -2.1626e+00,  3.7098e-03,  7.4183e-01,\n",
      "         -6.1434e-03, -5.3573e-01, -1.5317e+00,  2.1468e+00,  2.0344e+00,\n",
      "          9.8490e-02,  6.1059e-01, -5.8081e-01, -3.7679e-01, -1.2239e+00,\n",
      "         -1.9290e-01, -9.8422e-01,  5.1044e-01,  6.3757e-01,  4.8730e-01,\n",
      "          1.6320e+00, -1.9444e+00, -7.0079e-01, -1.8975e+00, -2.1706e-01,\n",
      "          7.9833e-01,  1.5412e+00, -9.0394e-01,  3.5279e-01,  8.2540e-01,\n",
      "         -6.4349e-01, -1.5015e+00, -1.4135e+00, -2.1457e-01,  1.3491e+00,\n",
      "         -1.4268e-01, -1.5797e+00,  2.3350e+00, -1.1054e+00, -1.2177e+00,\n",
      "          2.2866e+00,  8.4499e-01, -1.6503e+00, -1.4002e-01,  1.3362e+00,\n",
      "          1.5561e+00, -5.5424e-01, -2.3291e+00,  2.6630e-02, -6.7469e-01,\n",
      "          9.1876e-01, -2.3267e-01, -1.0202e-02, -1.5048e-01,  8.4816e-01,\n",
      "          1.1714e+00,  9.3529e-01,  3.7590e-01, -1.4612e+00,  3.4056e-01,\n",
      "         -1.5454e+00,  7.8555e-01, -1.8305e+00, -1.4714e+00,  1.9359e-01,\n",
      "          1.4036e+00, -9.3472e-01,  6.8212e-01,  6.1308e-01, -2.4329e-01,\n",
      "         -8.6914e-01,  2.8488e-01, -1.4122e+00,  1.7283e+00, -5.4997e-01,\n",
      "         -9.9698e-01, -1.9966e-01,  6.2254e-01, -2.5128e-01,  1.9040e+00,\n",
      "         -1.9626e+00,  8.4733e-01,  6.6324e-01,  1.3793e+00,  1.3690e+00,\n",
      "          7.0153e-01,  4.7340e-01, -2.2515e-01,  1.0881e+00, -1.4967e+00,\n",
      "          9.0632e-02, -3.2158e-01,  1.2538e+00, -6.3681e-01,  3.1044e-01,\n",
      "         -1.0878e+00,  3.6486e-01, -1.4618e-01, -6.2441e-01, -1.5341e+00,\n",
      "         -5.9983e-01, -7.5214e-02, -1.1611e+00, -1.9479e+00, -3.7174e-02,\n",
      "         -1.0956e+00, -1.5725e-01,  1.9629e-01, -7.8744e-01, -8.0346e-02,\n",
      "         -1.8891e-01, -4.8689e-01, -5.3722e-01, -6.1964e-01,  4.6030e-01,\n",
      "          1.1850e+00, -8.7388e-01,  1.4974e-01,  2.5488e-01,  7.7166e-02,\n",
      "          8.8471e-01,  2.8432e-02, -1.8526e+00, -1.9604e-01, -1.2686e+00,\n",
      "          5.6301e-01,  3.6899e-01,  9.7787e-01, -4.0194e-01, -1.2905e-01,\n",
      "         -1.8485e+00, -1.1435e+00, -1.3759e+00, -4.7894e-01, -5.9291e-01,\n",
      "         -2.4176e+00,  8.0561e-01, -1.1373e+00, -3.3925e-01, -3.3015e-02,\n",
      "          9.1512e-01, -7.7117e-01,  7.8743e-02,  1.4070e+00,  2.6107e+00,\n",
      "          5.7483e-01,  1.7722e+00,  9.8866e-01, -9.1852e-01, -6.4480e-01,\n",
      "         -2.8775e-01, -1.0557e+00, -6.4951e-02,  2.1890e-01,  1.8450e+00,\n",
      "         -4.9581e-01, -5.4616e-01,  1.2773e-01,  1.0773e+00, -1.2759e+00,\n",
      "          1.2737e+00,  1.4749e-02, -1.3043e+00, -1.4158e-01, -9.3276e-01,\n",
      "          3.0721e-01,  3.9986e-01, -6.8266e-01,  5.9389e-01, -1.9715e-01,\n",
      "          1.2295e+00,  1.4050e-01, -1.1182e-01, -1.4095e+00, -8.3039e-03,\n",
      "         -2.8357e-02,  7.4483e-01, -1.3121e-01, -2.5442e-01,  3.8845e-02,\n",
      "         -1.1970e+00, -6.2250e-01, -1.1900e-01,  8.8136e-01, -3.8020e-01,\n",
      "         -5.0512e-01,  2.0985e-01,  5.0237e-01,  5.3139e-01,  6.0648e-01,\n",
      "          3.7710e-01,  2.0093e-01,  3.4229e-01, -1.6924e+00,  2.5725e+00,\n",
      "          3.4574e-01, -2.5801e+00, -3.2960e-01,  1.0804e+00,  2.0598e-01,\n",
      "         -1.5458e+00, -5.9330e-01,  5.2782e-01,  5.6357e-01, -5.9840e-01,\n",
      "          7.3445e-01,  8.1289e-01,  3.1047e-01, -7.9667e-01, -5.5391e-01,\n",
      "         -6.0170e-01, -8.5040e-01,  8.8901e-01, -3.3804e-01,  1.3846e+00,\n",
      "          1.3054e+00, -1.2443e-01,  1.6678e-01,  4.6137e-01,  1.0569e-02,\n",
      "         -6.0181e-01,  6.1923e-01, -2.0383e+00, -3.8509e-01, -3.6891e-01,\n",
      "          1.6618e+00, -2.0217e+00, -2.9840e-01,  5.1748e-01,  2.8185e-01,\n",
      "          5.6501e-01, -8.5036e-01, -1.0018e+00,  5.1864e-01,  7.1640e-01,\n",
      "         -1.5945e+00,  1.6134e+00, -8.4588e-02, -2.2212e+00, -1.6109e+00,\n",
      "          1.9980e+00,  5.5465e-01,  1.4970e-01,  4.3207e-01,  4.0341e-01,\n",
      "          1.9695e+00,  5.7900e-01,  5.9839e-01, -1.1569e+00,  1.2753e+00,\n",
      "          5.6316e-01, -1.2627e-01,  9.4229e-01, -4.3236e-01,  2.2925e+00,\n",
      "         -1.1157e+00, -1.5529e+00, -9.5505e-01, -8.4812e-01, -7.2085e-01,\n",
      "          1.2537e+00, -1.5891e-01,  5.5072e-01, -1.2721e+00, -1.0878e+00,\n",
      "         -2.9280e-01, -2.2315e-01,  1.1159e+00,  3.4319e-01,  1.7817e+00,\n",
      "         -3.2019e-01,  8.0908e-01,  3.6969e-01,  2.1714e-01,  8.1509e-01,\n",
      "          6.5064e-01, -1.1522e+00, -6.7994e-01,  4.0951e-01, -9.5563e-01,\n",
      "         -6.6154e-01, -6.7173e-01, -4.1248e-02, -9.7033e-01,  3.0382e-01,\n",
      "         -5.7216e-01,  1.9123e-01,  1.3606e+00,  2.8770e-01,  1.0204e+00,\n",
      "         -3.9222e-01, -6.4810e-01,  2.5219e-01, -1.9757e-01, -4.5715e-01,\n",
      "          3.1052e-01, -1.1395e+00, -1.1568e-01, -8.4754e-01, -3.5625e-01,\n",
      "         -3.5624e-01, -1.7279e+00,  8.8424e-01,  1.0507e+00,  4.2059e-01,\n",
      "          1.8572e+00, -3.8163e-01,  1.8230e+00,  1.7469e-02,  9.1243e-01,\n",
      "          3.4272e-02,  1.3345e+00,  9.5969e-02,  3.6474e-01, -6.9674e-02,\n",
      "         -5.3041e-01, -8.8151e-01, -5.4083e-01,  3.5605e-01,  2.2961e-01,\n",
      "          3.1417e-01, -4.3712e-01,  8.0929e-01, -3.7364e-01, -1.5332e-01,\n",
      "          7.3486e-01,  4.2925e-01, -1.0193e+00,  1.0271e+00, -2.6854e+00,\n",
      "          3.8922e-01,  5.5149e-01,  8.3336e-01,  1.5611e+00,  8.1975e-01,\n",
      "          1.7160e+00, -7.7217e-01, -1.2188e+00, -3.2716e-01,  5.6547e-02,\n",
      "          2.1465e+00,  1.1669e-01, -7.8185e-01, -1.1585e+00,  8.2807e-01,\n",
      "          1.0402e-01,  2.1892e-01,  1.3676e+00,  6.0757e-01,  3.0176e-01,\n",
      "          4.1552e-02, -2.1528e+00,  9.9614e-01,  6.8129e-01, -1.0268e+00,\n",
      "          1.9474e-01,  1.4894e+00, -4.9238e-01, -4.7078e-02,  1.0373e+00,\n",
      "         -1.0338e+00, -3.2740e+00, -6.7008e-01, -2.7953e-01, -1.9544e-01,\n",
      "          1.1624e-01,  6.1003e-01,  3.0670e-01, -1.4326e+00, -2.2920e+00,\n",
      "         -2.5037e-01, -3.5627e-01,  4.8846e-02, -1.5668e+00, -4.6750e-01,\n",
      "         -6.9689e-01, -7.8805e-02,  4.2881e-01,  3.2417e-01,  8.1972e-01,\n",
      "         -3.2078e-01,  5.9137e-01, -1.7185e-01, -1.7781e-01, -7.8897e-02,\n",
      "         -1.2847e+00,  6.2094e-01, -3.7843e-01,  1.4600e+00,  2.3800e+00,\n",
      "          6.5078e-01, -8.5806e-01,  1.7515e-01, -4.3466e-01, -4.2210e-01,\n",
      "          5.2298e-01, -4.4647e-01,  1.3189e+00,  1.0428e-01, -2.7633e-01,\n",
      "         -2.0086e-01,  8.9630e-01, -3.9473e-01,  6.2863e-01,  6.1288e-01,\n",
      "         -9.7687e-01,  7.9885e-01, -1.6974e+00, -1.9441e-01,  4.3294e-02,\n",
      "          9.8346e-02, -9.0287e-01, -1.4228e+00,  1.3029e-01, -6.0851e-01,\n",
      "          2.7689e+00, -1.4116e+00,  1.3809e-01, -7.8693e-01,  3.1216e-01,\n",
      "          2.6224e+00,  9.8999e-01, -1.7620e+00,  1.6155e+00,  1.4590e+00,\n",
      "          1.7585e+00, -1.6705e-01, -6.8983e-01,  1.6876e-01, -8.7115e-01,\n",
      "         -1.2040e+00, -4.1341e-01, -3.3692e-01,  1.8508e-01,  3.4264e-01,\n",
      "         -8.9091e-01,  1.7252e-01, -1.2203e+00,  1.5964e+00, -1.9053e-01,\n",
      "          8.1263e-01, -4.3578e-02,  1.6775e-02,  1.5557e+00,  4.3743e-02,\n",
      "         -3.3109e-02,  6.8094e-01,  9.1650e-01,  5.6333e-01, -9.6928e-01,\n",
      "          4.5554e-01,  3.0660e-01,  1.0075e+00,  6.9422e-01,  7.8695e-02,\n",
      "         -2.7406e-01,  1.5972e+00, -7.5535e-01,  1.9649e-02,  2.4561e-01,\n",
      "         -4.6557e-01, -6.8894e-01, -1.1767e-01,  1.1910e+00,  6.5861e-01,\n",
      "         -1.8617e+00,  1.4942e+00,  3.7909e-01, -7.9171e-01,  2.7011e-01,\n",
      "          9.0609e-01, -3.6854e-02,  2.0012e+00, -3.2465e-02,  6.6056e-02,\n",
      "          1.1276e+00, -6.3257e-01, -7.3347e-02, -4.5324e-01,  3.7135e-01,\n",
      "          5.1418e-01,  1.0709e-01, -5.5073e-01, -7.6002e-01,  2.4416e-01,\n",
      "          4.7786e-01,  9.2906e-01,  8.2583e-01,  6.8162e-01, -5.0842e-01,\n",
      "         -2.9898e-01,  1.2785e+00,  2.4735e+00,  1.9211e+00,  8.7150e-01,\n",
      "          7.2129e-01,  4.3701e-01, -1.5937e+00,  1.8303e+00, -5.4659e-04,\n",
      "         -6.2536e-01,  4.2028e-01,  2.7104e-01, -5.2161e-01,  1.0857e+00,\n",
      "          2.1133e-01, -7.5490e-03,  5.6152e-03, -4.2657e-01, -2.1444e-02,\n",
      "         -1.0166e+00, -2.4634e-01, -1.1396e+00, -2.4348e+00, -6.3091e-03,\n",
      "         -6.1236e-01,  6.4089e-01,  3.0048e-01,  1.0086e+00, -1.1244e+00,\n",
      "         -1.5483e+00,  9.6688e-01, -3.0940e-02, -9.3227e-01,  1.2912e+00,\n",
      "          1.7201e-01,  1.3300e+00,  1.0965e+00,  5.0323e-01,  2.7750e-01,\n",
      "          1.5404e+00, -1.4024e-01,  1.5156e+00,  4.3890e-01, -9.7131e-01,\n",
      "         -7.0570e-01, -3.1476e-01,  6.2716e-01, -8.1971e-01,  7.2192e-01,\n",
      "          1.3222e+00, -4.8368e-02,  1.7672e+00, -8.9536e-01, -4.7180e-01,\n",
      "          1.8920e+00, -5.2235e-01, -4.3825e-01,  1.2090e+00,  3.5357e+00,\n",
      "          4.2685e-01, -1.0314e+00, -1.3299e-01,  6.2869e-01, -8.0460e-01,\n",
      "         -3.4371e-01, -6.8035e-01, -9.2776e-02,  2.3969e-02,  5.0095e-02,\n",
      "          1.2219e+00, -1.5676e+00, -7.0168e-01,  1.3532e+00, -3.7415e-01,\n",
      "         -6.7561e-01, -1.7235e-02,  1.8402e-01, -7.2019e-01, -2.9320e-01,\n",
      "         -1.1332e+00,  8.5277e-01,  5.4623e-01,  1.5881e+00, -9.6286e-01,\n",
      "          1.8032e+00,  1.1343e+00,  1.2661e+00, -3.2413e-01, -3.9401e-01,\n",
      "         -7.3789e-01, -8.7134e-01,  1.3119e+00,  7.2944e-01,  1.3908e+00,\n",
      "          2.2127e+00,  6.6411e-01,  1.3617e-01, -2.1563e+00,  1.1916e+00,\n",
      "         -1.4483e+00,  3.0384e-02,  5.1484e-01,  1.2259e-01, -9.8851e-01,\n",
      "          2.4835e+00,  9.2883e-01, -1.2084e-02,  8.2329e-01,  1.0679e+00,\n",
      "         -2.2373e-01,  6.6601e-01, -8.2939e-01,  1.5345e+00,  2.2225e-01,\n",
      "          9.7048e-01, -4.6719e-01,  1.0916e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.decoder._Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-multilingual-cased\", cache_dir='./cache/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/archive/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(idx)\n",
    "        text = self.df.iloc[idx]['ABSTRACT']\n",
    "        label = torch.tensor([self.df.iloc[idx][i] for i in [\"Computer Science\",\"Physics\",\"Mathematics\",\"Statistics\",\"Quantitative Biology\",\"Quantitative Finance\"]])\n",
    "        return text, label\n",
    "        # return self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=128), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    # print(texts)\n",
    "    return tokenizer(texts, return_tensors='pt', padding='max_length', truncation=True, max_length=512).to(device=DEV_CONF.device), torch.stack(labels).to(DEV_CONF.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(train, tokenizer)\n",
    "\n",
    "datasize = len(dataset)\n",
    "splitIndex = int(datasize * 0.2)\n",
    "trainDataSize = datasize - splitIndex\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [trainDataSize, splitIndex])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, collate_fn=collect_fn, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, collate_fn=collect_fn, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "epochs = 1\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, train_loader, loss_fn, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, label) in enumerate(train_loader):\n",
    "            # print(data['input_ids'])\n",
    "            # break\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**data)#, NoGradBert=False)\n",
    "            loss = loss_fn(output, label.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 100 == 99:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Batch {i+1}/{len(train_loader)} - Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Batch 100/2098 - Loss: 0.36848533153533936\n",
      "Epoch 1/1 - Batch 200/2098 - Loss: 0.321755975484848\n",
      "Epoch 1/1 - Batch 300/2098 - Loss: 0.5310551524162292\n",
      "Epoch 1/1 - Batch 400/2098 - Loss: 0.26477938890457153\n",
      "Epoch 1/1 - Batch 500/2098 - Loss: 0.2662111222743988\n",
      "Epoch 1/1 - Batch 600/2098 - Loss: 0.2252422571182251\n",
      "Epoch 1/1 - Batch 700/2098 - Loss: 0.14750906825065613\n",
      "Epoch 1/1 - Batch 800/2098 - Loss: 0.22241860628128052\n",
      "Epoch 1/1 - Batch 900/2098 - Loss: 0.31430137157440186\n",
      "Epoch 1/1 - Batch 1000/2098 - Loss: 0.1819993257522583\n",
      "Epoch 1/1 - Batch 1100/2098 - Loss: 0.37738537788391113\n",
      "Epoch 1/1 - Batch 1200/2098 - Loss: 0.2848208546638489\n",
      "Epoch 1/1 - Batch 1300/2098 - Loss: 0.2475285530090332\n",
      "Epoch 1/1 - Batch 1400/2098 - Loss: 0.13623857498168945\n",
      "Epoch 1/1 - Batch 1500/2098 - Loss: 0.2045365869998932\n",
      "Epoch 1/1 - Batch 1600/2098 - Loss: 0.2803414762020111\n",
      "Epoch 1/1 - Batch 1700/2098 - Loss: 0.2721858024597168\n",
      "Epoch 1/1 - Batch 1800/2098 - Loss: 0.3539148271083832\n",
      "Epoch 1/1 - Batch 1900/2098 - Loss: 0.11355720460414886\n",
      "Epoch 1/1 - Batch 2000/2098 - Loss: 0.2165650725364685\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_fn(model, train_loader, loss_fn, optimizer, epochs)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 6.0368e-01, -8.1372e-01, -1.3034e+00,  7.6100e-01, -6.2226e-01,\n",
      "         -3.5416e-01,  2.9610e-01,  2.2619e-01,  6.9881e-01, -2.7238e-01,\n",
      "         -6.3697e-01,  7.7920e-02, -7.7544e-01,  1.1514e-01, -1.9940e+00,\n",
      "         -1.2938e-01,  2.4391e-01,  4.2925e-02, -3.7178e-01,  5.0495e-01,\n",
      "         -6.2293e-01,  6.4387e-01,  7.8746e-01, -1.3177e+00, -2.6376e-01,\n",
      "          6.3053e-01, -7.6249e-01, -2.2444e-01,  6.4225e-01, -4.4528e-01,\n",
      "         -4.4119e-01,  1.8330e-02, -1.2461e+00, -4.8435e-01, -4.3747e-01,\n",
      "         -5.5416e-01, -1.4390e+00, -6.4568e-01, -8.7843e-01,  5.6404e-01,\n",
      "          1.0990e-01,  4.4082e-01,  7.1394e-01, -7.7282e-01,  1.2581e+00,\n",
      "          2.8174e-01, -8.2885e-01, -7.0741e-01,  1.4150e+00, -1.3309e+00,\n",
      "         -1.4537e-01,  3.8782e-01,  9.2136e-01,  1.0229e+00,  1.4751e-01,\n",
      "          7.7730e-01,  2.6152e-01,  7.4567e-01,  4.7614e-01, -2.8120e-01,\n",
      "          8.0779e-01, -2.2239e+00,  1.8151e-01, -1.1765e+00, -2.0418e+00,\n",
      "          1.2163e+00, -1.1649e-01, -1.7747e+00,  2.5938e-01,  1.4632e-01,\n",
      "         -1.3942e+00, -4.9843e-01, -2.4278e+00, -4.6980e-01,  1.7634e+00,\n",
      "         -5.8521e-01,  3.9518e-01,  6.1505e-01, -8.7736e-01, -3.3528e-01,\n",
      "          1.0686e+00, -2.8516e-01, -9.3192e-02, -8.4167e-01,  1.0694e+00,\n",
      "         -1.9353e-01,  8.7698e-02,  4.3993e-01,  9.7309e-01,  8.8515e-01,\n",
      "         -4.1592e-01, -1.1419e+00, -7.9527e-01, -5.9670e-01, -7.2373e-01,\n",
      "          1.2754e-01,  1.0378e+00, -6.1203e-01, -1.1691e+00,  4.2214e-01,\n",
      "         -1.8009e-01, -5.3168e-01, -9.3595e-01,  7.8205e-01, -6.5414e-01,\n",
      "         -7.9408e-01,  2.1333e-01,  8.1055e-02, -3.1666e-01, -9.1894e-01,\n",
      "          1.3027e+00,  1.0163e+00, -1.3855e+00, -1.5281e+00,  1.8518e+00,\n",
      "         -1.2835e+00,  5.5345e-01, -6.5420e-01,  7.8382e-01, -5.7286e-01,\n",
      "          2.7759e-01,  8.1347e-01,  8.4525e-01,  2.4051e-01, -2.4901e-01,\n",
      "         -1.0154e+00,  1.3156e+00, -3.0560e-01, -4.7495e-02, -9.9091e-01,\n",
      "          3.5619e-01,  8.9494e-01,  1.8247e+00,  1.1498e+00, -1.3757e-01,\n",
      "         -7.7314e-01,  1.3921e+00,  2.8517e-01, -2.4607e+00,  5.5532e-01,\n",
      "         -1.0542e+00, -6.6165e-01, -1.0956e+00,  2.4819e-01, -4.9534e-01,\n",
      "         -5.2699e-01, -2.2029e+00, -5.7487e-01,  1.1662e+00,  9.2109e-01,\n",
      "          1.3973e+00, -8.2791e-01,  7.5045e-01, -3.3854e-01, -6.7086e-01,\n",
      "         -2.4075e-01,  1.0521e+00,  7.5078e-01, -8.4077e-01,  5.4286e-01,\n",
      "          6.0187e-01,  1.4655e+00, -2.1620e+00,  3.8549e-03,  7.4139e-01,\n",
      "         -6.3796e-03, -5.3584e-01, -1.5311e+00,  2.1460e+00,  2.0334e+00,\n",
      "          9.8436e-02,  6.1050e-01, -5.8044e-01, -3.7645e-01, -1.2233e+00,\n",
      "         -1.9290e-01, -9.8375e-01,  5.1028e-01,  6.3728e-01,  4.8703e-01,\n",
      "          1.6311e+00, -1.9440e+00, -7.0061e-01, -1.8969e+00, -2.1694e-01,\n",
      "          7.9786e-01,  1.5406e+00, -9.0343e-01,  3.5257e-01,  8.2491e-01,\n",
      "         -6.4315e-01, -1.5009e+00, -1.4131e+00, -2.1451e-01,  1.3486e+00,\n",
      "         -1.4252e-01, -1.5790e+00,  2.3343e+00, -1.1048e+00, -1.2174e+00,\n",
      "          2.2854e+00,  8.4474e-01, -1.6497e+00, -1.4007e-01,  1.3357e+00,\n",
      "          1.5554e+00, -5.5411e-01, -2.3282e+00,  2.6792e-02, -6.7454e-01,\n",
      "          9.1848e-01, -2.3229e-01, -1.0103e-02, -1.5027e-01,  8.4779e-01,\n",
      "          1.1710e+00,  9.3499e-01,  3.7576e-01, -1.4606e+00,  3.4035e-01,\n",
      "         -1.5447e+00,  7.8523e-01, -1.8297e+00, -1.4710e+00,  1.9353e-01,\n",
      "          1.4031e+00, -9.3437e-01,  6.8163e-01,  6.1312e-01, -2.4306e-01,\n",
      "         -8.6861e-01,  2.8482e-01, -1.4116e+00,  1.7275e+00, -5.4969e-01,\n",
      "         -9.9633e-01, -1.9966e-01,  6.2247e-01, -2.5119e-01,  1.9031e+00,\n",
      "         -1.9616e+00,  8.4697e-01,  6.6285e-01,  1.3788e+00,  1.3685e+00,\n",
      "          7.0137e-01,  4.7315e-01, -2.2497e-01,  1.0877e+00, -1.4963e+00,\n",
      "          9.0793e-02, -3.2162e-01,  1.2531e+00, -6.3657e-01,  3.1043e-01,\n",
      "         -1.0876e+00,  3.6484e-01, -1.4621e-01, -6.2428e-01, -1.5335e+00,\n",
      "         -5.9962e-01, -7.5243e-02, -1.1605e+00, -1.9471e+00, -3.7158e-02,\n",
      "         -1.0952e+00, -1.5728e-01,  1.9618e-01, -7.8698e-01, -8.0154e-02,\n",
      "         -1.8881e-01, -4.8669e-01, -5.3711e-01, -6.1945e-01,  4.6014e-01,\n",
      "          1.1847e+00, -8.7371e-01,  1.4962e-01,  2.5494e-01,  7.6831e-02,\n",
      "          8.8437e-01,  2.8219e-02, -1.8517e+00, -1.9602e-01, -1.2680e+00,\n",
      "          5.6304e-01,  3.6897e-01,  9.7740e-01, -4.0183e-01, -1.2905e-01,\n",
      "         -1.8478e+00, -1.1432e+00, -1.3754e+00, -4.7860e-01, -5.9289e-01,\n",
      "         -2.4167e+00,  8.0545e-01, -1.1368e+00, -3.3912e-01, -3.2945e-02,\n",
      "          9.1487e-01, -7.7078e-01,  7.8997e-02,  1.4064e+00,  2.6096e+00,\n",
      "          5.7458e-01,  1.7715e+00,  9.8831e-01, -9.1807e-01, -6.4462e-01,\n",
      "         -2.8764e-01, -1.0553e+00, -6.4742e-02,  2.1886e-01,  1.8439e+00,\n",
      "         -4.9561e-01, -5.4607e-01,  1.2767e-01,  1.0767e+00, -1.2755e+00,\n",
      "          1.2729e+00,  1.4669e-02, -1.3037e+00, -1.4148e-01, -9.3235e-01,\n",
      "          3.0714e-01,  3.9965e-01, -6.8249e-01,  5.9354e-01, -1.9709e-01,\n",
      "          1.2291e+00,  1.4049e-01, -1.1168e-01, -1.4088e+00, -8.3334e-03,\n",
      "         -2.8406e-02,  7.4453e-01, -1.3103e-01, -2.5413e-01,  3.8791e-02,\n",
      "         -1.1966e+00, -6.2196e-01, -1.1890e-01,  8.8105e-01, -3.8021e-01,\n",
      "         -5.0483e-01,  2.0985e-01,  5.0211e-01,  5.3101e-01,  6.0612e-01,\n",
      "          3.7647e-01,  2.0088e-01,  3.4208e-01, -1.6916e+00,  2.5713e+00,\n",
      "          3.4549e-01, -2.5792e+00, -3.2957e-01,  1.0800e+00,  2.0597e-01,\n",
      "         -1.5449e+00, -5.9294e-01,  5.2758e-01,  5.6317e-01, -5.9820e-01,\n",
      "          7.3433e-01,  8.1253e-01,  3.1038e-01, -7.9642e-01, -5.5366e-01,\n",
      "         -6.0134e-01, -8.4998e-01,  8.8848e-01, -3.3803e-01,  1.3841e+00,\n",
      "          1.3050e+00, -1.2427e-01,  1.6663e-01,  4.6099e-01,  1.0520e-02,\n",
      "         -6.0146e-01,  6.1891e-01, -2.0375e+00, -3.8505e-01, -3.6915e-01,\n",
      "          1.6607e+00, -2.0205e+00, -2.9826e-01,  5.1751e-01,  2.8200e-01,\n",
      "          5.6495e-01, -8.4981e-01, -1.0013e+00,  5.1825e-01,  7.1621e-01,\n",
      "         -1.5935e+00,  1.6129e+00, -8.4510e-02, -2.2203e+00, -1.6099e+00,\n",
      "          1.9971e+00,  5.5460e-01,  1.4979e-01,  4.3168e-01,  4.0327e-01,\n",
      "          1.9689e+00,  5.7861e-01,  5.9813e-01, -1.1564e+00,  1.2748e+00,\n",
      "          5.6291e-01, -1.2612e-01,  9.4182e-01, -4.3204e-01,  2.2914e+00,\n",
      "         -1.1152e+00, -1.5523e+00, -9.5467e-01, -8.4764e-01, -7.2049e-01,\n",
      "          1.2534e+00, -1.5907e-01,  5.5049e-01, -1.2714e+00, -1.0874e+00,\n",
      "         -2.9258e-01, -2.2280e-01,  1.1156e+00,  3.4323e-01,  1.7809e+00,\n",
      "         -3.1992e-01,  8.0892e-01,  3.6919e-01,  2.1704e-01,  8.1466e-01,\n",
      "          6.5037e-01, -1.1518e+00, -6.7967e-01,  4.0939e-01, -9.5528e-01,\n",
      "         -6.6109e-01, -6.7155e-01, -4.1163e-02, -9.6981e-01,  3.0373e-01,\n",
      "         -5.7208e-01,  1.9121e-01,  1.3603e+00,  2.8762e-01,  1.0199e+00,\n",
      "         -3.9208e-01, -6.4798e-01,  2.5239e-01, -1.9728e-01, -4.5689e-01,\n",
      "          3.1043e-01, -1.1391e+00, -1.1558e-01, -8.4701e-01, -3.5605e-01,\n",
      "         -3.5609e-01, -1.7272e+00,  8.8379e-01,  1.0503e+00,  4.2054e-01,\n",
      "          1.8564e+00, -3.8149e-01,  1.8223e+00,  1.7237e-02,  9.1184e-01,\n",
      "          3.4207e-02,  1.3341e+00,  9.5974e-02,  3.6457e-01, -6.9503e-02,\n",
      "         -5.3028e-01, -8.8124e-01, -5.4067e-01,  3.5588e-01,  2.2949e-01,\n",
      "          3.1399e-01, -4.3683e-01,  8.0892e-01, -3.7368e-01, -1.5339e-01,\n",
      "          7.3469e-01,  4.2914e-01, -1.0189e+00,  1.0267e+00, -2.6845e+00,\n",
      "          3.8917e-01,  5.5144e-01,  8.3300e-01,  1.5603e+00,  8.1952e-01,\n",
      "          1.7153e+00, -7.7195e-01, -1.2183e+00, -3.2713e-01,  5.6641e-02,\n",
      "          2.1455e+00,  1.1664e-01, -7.8149e-01, -1.1580e+00,  8.2768e-01,\n",
      "          1.0392e-01,  2.1880e-01,  1.3673e+00,  6.0713e-01,  3.0151e-01,\n",
      "          4.1591e-02, -2.1519e+00,  9.9570e-01,  6.8090e-01, -1.0262e+00,\n",
      "          1.9472e-01,  1.4889e+00, -4.9225e-01, -4.6961e-02,  1.0368e+00,\n",
      "         -1.0334e+00, -3.2725e+00, -6.6998e-01, -2.7955e-01, -1.9541e-01,\n",
      "          1.1620e-01,  6.0977e-01,  3.0682e-01, -1.4319e+00, -2.2909e+00,\n",
      "         -2.5034e-01, -3.5623e-01,  4.8719e-02, -1.5662e+00, -4.6738e-01,\n",
      "         -6.9643e-01, -7.8703e-02,  4.2866e-01,  3.2390e-01,  8.1956e-01,\n",
      "         -3.2074e-01,  5.9116e-01, -1.7199e-01, -1.7791e-01, -7.8770e-02,\n",
      "         -1.2842e+00,  6.2062e-01, -3.7817e-01,  1.4596e+00,  2.3791e+00,\n",
      "          6.5069e-01, -8.5780e-01,  1.7516e-01, -4.3434e-01, -4.2176e-01,\n",
      "          5.2293e-01, -4.4643e-01,  1.3184e+00,  1.0429e-01, -2.7647e-01,\n",
      "         -2.0087e-01,  8.9599e-01, -3.9454e-01,  6.2827e-01,  6.1239e-01,\n",
      "         -9.7636e-01,  7.9818e-01, -1.6967e+00, -1.9415e-01,  4.3177e-02,\n",
      "          9.8340e-02, -9.0245e-01, -1.4219e+00,  1.3031e-01, -6.0835e-01,\n",
      "          2.7676e+00, -1.4107e+00,  1.3817e-01, -7.8659e-01,  3.1195e-01,\n",
      "          2.6215e+00,  9.8927e-01, -1.7613e+00,  1.6149e+00,  1.4586e+00,\n",
      "          1.7576e+00, -1.6704e-01, -6.8960e-01,  1.6886e-01, -8.7074e-01,\n",
      "         -1.2036e+00, -4.1324e-01, -3.3674e-01,  1.8481e-01,  3.4243e-01,\n",
      "         -8.9058e-01,  1.7232e-01, -1.2199e+00,  1.5955e+00, -1.9043e-01,\n",
      "          8.1233e-01, -4.3618e-02,  1.7045e-02,  1.5546e+00,  4.3873e-02,\n",
      "         -3.3033e-02,  6.8083e-01,  9.1606e-01,  5.6306e-01, -9.6878e-01,\n",
      "          4.5525e-01,  3.0651e-01,  1.0071e+00,  6.9390e-01,  7.8600e-02,\n",
      "         -2.7403e-01,  1.5965e+00, -7.5501e-01,  1.9618e-02,  2.4554e-01,\n",
      "         -4.6552e-01, -6.8866e-01, -1.1762e-01,  1.1905e+00,  6.5847e-01,\n",
      "         -1.8608e+00,  1.4938e+00,  3.7896e-01, -7.9126e-01,  2.7009e-01,\n",
      "          9.0572e-01, -3.6900e-02,  2.0002e+00, -3.2358e-02,  6.6070e-02,\n",
      "          1.1270e+00, -6.3234e-01, -7.3398e-02, -4.5305e-01,  3.7108e-01,\n",
      "          5.1410e-01,  1.0696e-01, -5.5055e-01, -7.5965e-01,  2.4419e-01,\n",
      "          4.7774e-01,  9.2871e-01,  8.2548e-01,  6.8102e-01, -5.0826e-01,\n",
      "         -2.9891e-01,  1.2783e+00,  2.4727e+00,  1.9202e+00,  8.7089e-01,\n",
      "          7.2113e-01,  4.3677e-01, -1.5928e+00,  1.8297e+00, -6.9269e-04,\n",
      "         -6.2521e-01,  4.2001e-01,  2.7106e-01, -5.2122e-01,  1.0855e+00,\n",
      "          2.1113e-01, -7.5336e-03,  5.7235e-03, -4.2627e-01, -2.1615e-02,\n",
      "         -1.0162e+00, -2.4611e-01, -1.1391e+00, -2.4337e+00, -6.3673e-03,\n",
      "         -6.1199e-01,  6.4063e-01,  3.0035e-01,  1.0081e+00, -1.1238e+00,\n",
      "         -1.5476e+00,  9.6630e-01, -3.0881e-02, -9.3199e-01,  1.2908e+00,\n",
      "          1.7219e-01,  1.3294e+00,  1.0960e+00,  5.0309e-01,  2.7754e-01,\n",
      "          1.5393e+00, -1.4025e-01,  1.5148e+00,  4.3870e-01, -9.7085e-01,\n",
      "         -7.0528e-01, -3.1460e-01,  6.2704e-01, -8.1918e-01,  7.2176e-01,\n",
      "          1.3219e+00, -4.8424e-02,  1.7660e+00, -8.9488e-01, -4.7169e-01,\n",
      "          1.8913e+00, -5.2187e-01, -4.3796e-01,  1.2084e+00,  3.5342e+00,\n",
      "          4.2669e-01, -1.0310e+00, -1.3284e-01,  6.2827e-01, -8.0419e-01,\n",
      "         -3.4365e-01, -6.8038e-01, -9.2760e-02,  2.4358e-02,  5.0043e-02,\n",
      "          1.2212e+00, -1.5668e+00, -7.0152e-01,  1.3527e+00, -3.7383e-01,\n",
      "         -6.7543e-01, -1.7322e-02,  1.8414e-01, -7.2022e-01, -2.9315e-01,\n",
      "         -1.1328e+00,  8.5237e-01,  5.4615e-01,  1.5874e+00, -9.6229e-01,\n",
      "          1.8022e+00,  1.1336e+00,  1.2654e+00, -3.2390e-01, -3.9367e-01,\n",
      "         -7.3764e-01, -8.7076e-01,  1.3116e+00,  7.2917e-01,  1.3902e+00,\n",
      "          2.2113e+00,  6.6394e-01,  1.3630e-01, -2.1553e+00,  1.1914e+00,\n",
      "         -1.4478e+00,  3.0291e-02,  5.1460e-01,  1.2247e-01, -9.8797e-01,\n",
      "          2.4827e+00,  9.2827e-01, -1.2009e-02,  8.2288e-01,  1.0675e+00,\n",
      "         -2.2347e-01,  6.6579e-01, -8.2902e-01,  1.5334e+00,  2.2191e-01,\n",
      "          9.7003e-01, -4.6705e-01,  1.0913e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.decoder._Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinationModel(\n",
       "  (distilBert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): SentiClassifier(\n",
       "    (mapper): CACBlocks(\n",
       "      (_mha): ModuleList(\n",
       "        (0-5): 6 x MHABlock(\n",
       "          (_mha): Attention(\n",
       "            (qProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (kvProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (outProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ffn): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (outNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outProj): Linear(in_features=768, out_features=6, bias=True)\n",
       "  (activate): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 0, 0, 0]], device='cuda:0')\n",
      "tensor([1, 0, 0, 0, 0, 0])\n",
      "tensor([[False,  True, False,  True,  True,  True]])\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "id = 13\n",
    "sample = tokenizer(dataset[id][0], return_tensors='pt', padding='max_length', truncation=True, max_length=512).to(device=DEV_CONF.device)\n",
    "output = torch.where(model(**sample) > 0.2, 1, 0)\n",
    "print(output)\n",
    "print(dataset[id][1])\n",
    "ans = torch.eq(output.to(\"cpu\"), dataset[id][1])\n",
    "print(ans)\n",
    "print(torch.all(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = [0] * 6\n",
    "# testdata = train.sample(1000)\n",
    "# test_dataset = MyDataset(testdata, tokenizer)\n",
    "\n",
    "# for data in test_dataset:\n",
    "#     # print(data[1][0])\n",
    "#     sample = tokenizer(data[0], return_tensors='pt', padding='max_length', truncation=True, max_length=512).to(device=DEV_CONF.device)\n",
    "#     output = torch.where(model(**sample) > 0.2, 1, 0)\n",
    "#     ansList = torch.eq(output.squeeze().to(\"cpu\"), data[1])\n",
    "#     for i, ans in enumerate(ansList):\n",
    "#         # print(ans)\n",
    "#         if ans:\n",
    "#             acc[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in .\\.venv\\lib\\site-packages (1.4.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.19.5 in .\\.venv\\lib\\site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in .\\.venv\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in .\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in .\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    acc = [0] * 6\n",
    "    for (data, label) in test_loader:\n",
    "        output = torch.where(model(**data) > 0.2, 1, 0)\n",
    "        ansList = torch.eq(output, label)\n",
    "        # print(ansList)\n",
    "        for ans in ansList:\n",
    "            for i, a in enumerate(ans):\n",
    "                if a:\n",
    "                    acc[i] += 1\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(model, test_loader)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ans \u001b[38;5;129;01min\u001b[39;00m ansList:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ans):\n\u001b[1;32m----> 9\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m a:\n\u001b[0;32m     10\u001b[0m                 acc[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8254649499284692, 0.8774439675727229, 0.8438245112064855, 0.8073438245112065, 0.9737720553171197, 0.9928469241773963]\n"
     ]
    }
   ],
   "source": [
    "print([i / splitIndex for i in acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- noGradBert\n",
    "\n",
    "[0.8483547925608012, 0.8457319980925131, 0.8612303290414879, 0.757033857892227, 0.9644730567477349, 0.9895088221268479]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GradBert\n",
    "\n",
    "[0.8254649499284692, 0.8774439675727229, 0.8438245112064855, 0.8073438245112065, 0.9737720553171197, 0.9928469241773963]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'weights/model-240515-1357.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('weights/model-240515-1336.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
